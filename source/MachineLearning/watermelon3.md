# 【西瓜书】线性模型

作者：wallace-lai <br/>
发布：2024-05-20 <br/>
更新：2024-05-20 <br/>

【pending】

本章的叙述逻辑：

（1）给出线性模型的基本形式

（2）介绍在线性模型之上的线性回归

（3）介绍单个属性时的线性回归模型的解法

（4）将单个属性的线性回归模型的解法推广到多元线性回归上

（5）介绍广义线性模型

（6）介绍广义线性模型的特例——对数几率回归，使用对数几率回归来解决分类问题

（7）介绍线性判别分析

（8）介绍多分类学习，即利用二分类学习器来解决多分类问题

（9）介绍如何解决类别不平衡问题

## 1. 基本形式

给定由$d$个属性描述的示例$\symbf{x} = (x_1;x_2;...;x_d)$，其中$x_i$是$\symbf{x}$在第$i$个属性上的取值，线性模型试图学得一个通过属性的线性组合来进行预测的函数，即：

$$
f(\symbf{x})=w_1x_1 + w_2x_2 + ... + w_dx_d + b
$$

一般用向量形式写成：

$$
f(\symbf{x}) = \symbf{w}^T\symbf{x} + b
$$

其中$\symbf{w} = (w_1;w_2;...;w_d)$，$\symbf{w}$和$b$学得之后，模型就得以确定。

## 2. 线性回归

什么是线性回归？很简单，线性回归就是利用线性模型尽可能准确地去预测输出。

先考虑最简单的情形，即输入属性的数目只有一个。此时，线性回归试图学得

$$
f(x_i) = wx_i + b,使得f(x_i) \simeq y_i
$$

为了确定$w$和$b$的值，鉴于均方误差是回归任务中最常用的性能度量，因此可以试图让均方误差最小化，即

$$
(w^*,b^*) = arg min
$$


没搞懂：
（1）式3.7的推导

（2）式3.10的推导

（3）非满秩矩阵时，引入正则项如何做？

