# 【西瓜书】决策树

作者：wallace-lai <br/>
发布：2024-03-15 <br/>
更新：2023-03-15 <br/>

## 4.1 基本流程

（1）什么是决策树？

一棵决策树包含一个**根结点**、若干个**内部结点**和若干个**叶结点**。

- 叶结点对应于决策结果，其他每个结点则对应于一个属性测试；

- 每个结点包含的样本集合根据属性测试的结果被划分到子结点中；

- 根结点包含样本全集；

从根结点到每个叶结点的路径对应了一个判定测试序列。决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树。

（2）决策树学习基本算法？

![决策树学习算法](../media/images/MachineLearning/watermelon0.png)



## 4.2 划分选择

## 4.3 剪枝处理

（1）剪枝是什么？

（2）为什么要剪枝？

（3）常见的剪枝方法？

## 4.4 连续与缺失值

## 4.5 多变量决策树


所以，对于决策树而言，最核心的问题是**如何度量所划分样本的纯度**？

## 一、信息熵

### 自信息

对于随机变量$X$来说，它的自信息定义为：

$$
I(X)=-\log _b p(x)
$$

当$b = 2$时，其单位为bit；当$b=e$时，其单位为nat。

定义信息熵为**自信息的期望**，用其来度量随机变量$X$的不确定性，信息熵越大说明其越不确定。

$$
H(X)=E[I(X)]=-\sum_x p(x) \log _b p(x)
$$

计算信息熵时约定：

（1）若$p(x) = 0$，则$p(x) \log _b p(x) = 0$；

（2）当$X$的某个取值的概率为1时信息熵最小（最确定），其值为0；

（3）当$X$的各个取值概率均等时信息熵最大（最不确定），其值为$\log _b |X|$；


## 二、ID3决策树



## 三、C4.5决策树

## 四、CART决策树

未完待续